<!doctype html>
<html>
<head>
	<title>WebRTC: Still photo capture demo</title>
	<base href="https://raw.githubusercontent.com/Azure-Samples/SpeechToText-WebSockets-Javascript/preview/samples/browser/Sample.html">
	<meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
	<meta charset='utf-8'>
	<link rel="stylesheet" href="main.css" type="text/css" media="all">


</head>
<body>
 	<div class="container" style="border:1px black solid;color:grey;">
    		<h1>Blind's Eye</h1>      
    		<p>&nbsp;&nbsp;&nbsp;&nbsp;-Helping People makes this world a better place.</p>    
	</div>
    <div id="content" style="display:none;margin:10px;">
        <table width="100%" style="margin:50px;">
            <tr>
                <td></td>
                
            </tr>
            <tr>
                
                <td><input id="key" type="hidden" size="40" value="dfe4fbcf03284f4cbe040ea67f8f4ac3"></td>
            </tr>
            <tr>
                
                <td >
			<input id="languageOptions" type="hidden" size="40" value="en-IN">
                    
                </td>
            </tr>
            <tr>
                
		<input id="recognitionMode" type="hidden" size="40" value="Dictation">
                
            </tr>
            <tr>
                <input id="formatOptions" type="hidden" size="40" value="Simple">
                
            </tr>
            <tr>
		<input id="inputSource" type="hidden" size="40" value="Mic">
         
                
            </tr>
            <tr>
                <td></td>
                <td>
		    <input id="startBtn" type="hidden" size="40" >
			<input id="startBtn" type="hidden" size="40" >
                    
                    <input type="file" id="filePicker" accept=".wav" style="display:none"/>
                </td>
            </tr>
            <tr>
                <td></td>
                <td>
                    <table>
                        <tr>
                            <td>Results:</td>
                            <td>Current hypothesis:</td>
                        </tr>
                        <tr>
                            
			
                            <td style="vertical-align: top">
                                <span id="hypothesisDiv" style="width:200px;height:200px;display:block;"></span>
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
            <tr>
                <td align="right">Status:</td>
                <td align="left"><span id="statusDiv"></span></td>
            </tr>
        </table>
    </div>

    <!-- SDK REFERENCE -->
    <script type="text/htmlpreview" src="../../distrib/speech.sdk.bundle.js"></script>

    <!-- SDK USAGE -->
    <script type="text/htmlpreview">
        // On document load resolve the SDK dependency
        function Initialize(onComplete) {
            if (!!window.SDK) {
                document.getElementById('content').style.display = 'block';
                document.getElementById('warning').style.display = 'none';
                onComplete(window.SDK);
            }
        }
        
        // Setup the recognizer
        function RecognizerSetup(SDK, recognitionMode, language, format, subscriptionKey) {
            
            switch (recognitionMode) {
                case "Interactive" :
                    recognitionMode = SDK.RecognitionMode.Interactive;    
                    break;
                case "Conversation" :
                    recognitionMode = SDK.RecognitionMode.Conversation;    
                    break;
                case "Dictation" :
                    recognitionMode = SDK.RecognitionMode.Dictation;    
                    break;
                default:
                    recognitionMode = SDK.RecognitionMode.Interactive;
            }

            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode,
                language, // Supported languages are specific to each recognition mode. Refer to docs.
                format); // SDK.SpeechResultFormat.Simple (Options - Simple/Detailed)


            var useTokenAuth = false;
            
            var authentication = function() {
                if (!useTokenAuth)
                    return new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

                var callback = function() {
                    var tokenDeferral = new SDK.Deferred();
                    try {
                        var xhr = new(XMLHttpRequest || ActiveXObject)('MSXML2.XMLHTTP.3.0');
                        xhr.open('GET', '/token', 1);
                        xhr.onload = function () {
                            if (xhr.status === 200)  {
                                tokenDeferral.Resolve(xhr.responseText);
                            } else {
                                tokenDeferral.Reject('Issue token request failed.');
                            }
                        };
                        xhr.send();
                    } catch (e) {
                        window.console && console.log(e);
                        tokenDeferral.Reject(e.message);
                    }
                    return tokenDeferral.Promise();
                }

                return new SDK.CognitiveTokenAuthentication(callback, callback);
            }();
            
            var files = document.getElementById('filePicker').files;
            if (!files.length) {
                return SDK.CreateRecognizer(recognizerConfig, authentication);
            } else {
                return SDK.CreateRecognizerWithFileAudioSource(recognizerConfig, authentication, files[0]);
            }
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {
            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */
                switch (event.Name) {
                    case "RecognitionTriggeredEvent" :
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent" :
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent" :
                        UpdateStatus("Listening_Recognizing");
                        break;
                    case "SpeechStartDetectedEvent" :
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text, false);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechFragmentEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text, true);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechEndDetectedEvent" :
                        OnSpeechEndDetected();
                        UpdateStatus("Processing_Adding_Final_Touches");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechSimplePhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "SpeechDetailedPhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent" :
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                    default:
                        console.log(JSON.stringify(event)); // Debug information
                }
            })
            .On(() => {
                // The request succeeded. Nothing to do here.
            },
            (error) => {
                console.error(error);
            });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
        }
    </script>

    <!-- Browser Hooks -->
    <script type="text/htmlpreview">
        var startBtn, stopBtn, hypothesisDiv, phraseDiv, statusDiv;
        var key, languageOptions, formatOptions, recognitionMode, inputSource, filePicker;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            //phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("hypothesisDiv");
            statusDiv = document.getElementById("statusDiv");
            key = document.getElementById("key");
            languageOptions = document.getElementById("languageOptions");
            formatOptions = document.getElementById("formatOptions");
            inputSource = document.getElementById("inputSource");
            recognitionMode = document.getElementById("recognitionMode");
            filePicker = document.getElementById('filePicker');

            languageOptions.addEventListener("change", Setup);
            formatOptions.addEventListener("change", Setup);
            recognitionMode.addEventListener("change", Setup);

            startbutton.addEventListener("click", function () {
                if (key.value == "" || key.value == "YOUR_BING_SPEECH_API_KEY") {
                    alert("Please enter your Bing Speech subscription key!");
                    return;
                }
                if (inputSource.value === "File") {
                    filePicker.click();
                } else {
                    if (!recognizer || previousSubscriptionKey != key.value) {
                        previousSubscriptionKey = key.value;
                        Setup();
                    }

                    hypothesisDiv.innerHTML = "";
                    //phraseDiv.innerHTML = "";
                    RecognizerStart(SDK, recognizer);
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                }                
            });

            key.addEventListener("focus", function () {
               if (key.value == "YOUR_BING_SPEECH_API_KEY") {
                   key.value = "";
               }
            });

            key.addEventListener("focusout", function () {
               if (key.value == "") {
                   key.value = "YOUR_BING_SPEECH_API_KEY";
               }
            });

            filePicker.addEventListener("change", function () {
                Setup();
                hypothesisDiv.innerHTML = "";
                //phraseDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
                filePicker.value = "";
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK, recognizer);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
            });
        });

        function Setup() {
            if (recognizer != null) {
                RecognizerStop(SDK, recognizer);
            }
            recognizer = RecognizerSetup(SDK, recognitionMode.value, languageOptions.value, SDK.SpeechResultFormat[formatOptions.value], key.value);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text, append) {
            if (append) 
                hypothesisDiv.innerHTML += text + " ";
            else 
                hypothesisDiv.innerHTML = text;

            var length = hypothesisDiv.innerHTML.length;
            if (length > 403) {
                hypothesisDiv.innerHTML = "..." + hypothesisDiv.innerHTML.substr(length-400, length);
            }
        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function UpdateRecognizedPhrase(json) {
            hypothesisDiv.innerHTML = "";
            //phraseDiv.innerHTML += json + "\n";
		save2.innerHTML += json + "?";
        }

        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    </script>
<script src="//htmlpreview.github.io/htmlpreview.min.js"></script><script>HTMLPreview.replaceAssets();</script>
<script>
	(function() {
  // The width and height of the captured photo. We will set the
  // width to the value defined here, but the height will be
  // calculated based on the aspect ratio of the input stream.

  var width = 600;    // We will scale the photo width to this
  var height = 0;     // This will be computed based on the input stream

  // |streaming| indicates whether or not we're currently streaming
  // video from the camera. Obviously, we start at false.

  var streaming = false;

  // The various HTML elements we need to configure or control. These
  // will be set by the startup() function.

  var video = null;
  var canvas = null;
  var photo = null;
  var startbutton = null;

  function startup() {
    video = document.getElementById('video');
    canvas = document.getElementById('canvas');
    photo = document.getElementById('photo');
    startbutton = document.getElementById('startbutton');

    navigator.getMedia = ( navigator.getUserMedia ||
                           navigator.webkitGetUserMedia ||
                           navigator.mozGetUserMedia ||
                           navigator.msGetUserMedia);

    navigator.getMedia(
      {
        video: true,
        audio: false
      },
      function(stream) {
        video.src = window.URL.createObjectURL(stream);
      },
      function(err) {
        console.log("An error occured! " + err);
      }
    );

    video.addEventListener('canplay', function(ev){
      if (!streaming) {
        height = video.videoHeight / (video.videoWidth/width);

        // Firefox currently has a bug where the height can't be read from
        // the video, so we will make assumptions if this happens.

        if (isNaN(height)) {
          height = width / (4/3);
        }

        video.setAttribute('width', width);
        video.setAttribute('height', height);
        canvas.setAttribute('width', width);
        canvas.setAttribute('height', height);
        streaming = true;
      }
    }, false);

    startbutton.addEventListener('click', function(ev){
      takepicture();
      ev.preventDefault();
    }, false);

    clearphoto();
  }

  // Fill the photo with an indication that none has been
  // captured.


  function clearphoto() {
    var context = canvas.getContext('2d');
    context.fillStyle = "#AAA";
    context.fillRect(0, 0, canvas.width, canvas.height);

    var data = canvas.toDataURL('image/png');
    photo.setAttribute('src', data);
  }
makeblob = function (dataURL) {
            var BASE64_MARKER = ';base64,';
            if (dataURL.indexOf(BASE64_MARKER) == -1) {
                var parts = dataURL.split(',');
                var contentType = parts[0].split(':')[1];
                var raw = decodeURIComponent(parts[1]);
                return new Blob([raw], { type: contentType });
            }
            var parts = dataURL.split(BASE64_MARKER);
            var contentType = parts[0].split(':')[1];
            var raw = window.atob(parts[1]);
            var rawLength = raw.length;

            var uInt8Array = new Uint8Array(rawLength);

            for (var i = 0; i < rawLength; ++i) {
                uInt8Array[i] = raw.charCodeAt(i);
            }

            return new Blob([uInt8Array], { type: contentType });
        }
  // Capture a photo by fetching the current contents of the video
  // and drawing it into a canvas, then converting that to a PNG
  // format data URL. By drawing it on an offscreen canvas and then
  // drawing that to the screen, we can change its size and/or apply
  // other changes before drawing it.

  function takepicture() {
    var context = canvas.getContext('2d');
    if (width && height) {
      canvas.width = width;
      canvas.height = height;
      context.drawImage(video, 0, 0, width, height);

      var data = canvas.toDataURL('image/png');
      photo1 = document.getElementById('photo1');
        photo1.value =data;

      photo.setAttribute('src', data);
    } else {
      clearphoto();
    }
  }

  // Set up our event listener to run the startup process
  // once loading is complete.
  window.addEventListener('load', startup, false);
})();


</script>
<div class="contentarea" style="margin-top:50px;">
<table width="100%">
<tr width="100%">
<td width="70%" align="center">
	<table width="50%">
		<tr width="100%">
		<td width="100%">	
		  <div class="camera" width="100%">
		    
		<video autoplay="true" id="video">Video stream not available.</video>
		</td>
		</tr>
		<tr width="100%">
		<td width="100%" align="center">
		    <button id="startbutton" style="width:350px;height:100px;" class="btn btn-primary">Take photo</button>
		</td>
		</tr>
	</table>
</td>
<td width="30%">
	<table width="50%">
		<tr width="100%">
		<td width="100%">
		    <form method="post" action="http://ec2-52-39-175-212.us-west-2.compute.amazonaws.com:8087/sample" width="100%">
			{% csrf_token %}
			<input type="hidden" name="photo1" id="photo1">
			<input type="hidden" name="save1" id="save1" >    
			<textarea type="text" name="save2" id="save2" rows="20" col="0" align="left" style="margin-left:20px;padding-left:0px;">   </textarea>
		</td>
		</tr>
		<tr width="100%">
		<td width="100%">
			<input type="submit" style="width:350px;height:100px;" class="btn btn-success">
		    </form>
		</td>
		</tr>
	</table>
</td>
</tr>
</table>
		  </div>
		  <canvas id="canvas">
		  </canvas>
		  <div class="output">
		    <img id="photo" alt="The screen capture will appear in this box.">
		  
</body>
</html>

